---
title: "Week 2: Getting A Groove"
date: 2019-02-08
---
## Week 2 
After kicking this week off, it took some time but I feel that I've got a groove I can get with to get things done! 
I was exposed to a lot of  new knowledge this week, so let me share with you my friends, some of the highlights  of what I enjoyed learning! 
I will organize this for you with the following categories: 
<ul>
    <li> Natural Language Processing: Word Embeddings  </li>
    <li> Reinforcement Learning: Multi-Armbed Bandit Problems </li>
    <li> Unsupervised Learning: AutoEncoders, K-Means Clustering </li>
</ul>
Let's get started! 

<h3> Natural Language Processing: Word Embeddings</h3>
My focus for NLP this week was learn vector representations of words. The initial approach was creating count based
matrices. The Word-Document matrix was created by looping through all available documents to create a matrix $$X$$, 
where element $$X_{i,j}$$ tells us if word $$i$$ appears in document $$j$$. This approach is not ideal because of how 
sparse the matrix is, even if it makes use of global statistics of the corpus.

The next attempt is is a Word-Based Co-Occurence Matrix. This matrix $$X_{i,j}$$ is created by looping through the corpus 
and counting how many times each word $$j$$ appears in the context of word $$i$$. This is another sparse matrix, and 
is thus still not ideal. This idea puts us in the line of reasoning of using the context of words. We are interested
in doing so because of the distributional hypothesis.

The distributional hypothesis is the idea that the a word's meaning is given by the words that frequently appear close
by to it. This gave rise to Word2Vec

Word2Vec is composed of two approaches to creating word embeddings, followed by two training methods. Word embeddings can
be generated using the Continuous Bag Of Words (CBOW) model, which aims to the predict a center word given some surrounding
 context, or the Skip-Gram Model, which aims to predict the distribution of context word given a center word. These embeddings can
 be trained using Negative Sampling, which defines an objective by sampling negative samples negative examples from a
 false corpus. These embeddings can also be trained using Hierarchical Soft-Max, which defines an objective using a 
 tree structure to compute probabilities for all words in our vocabulary. 
 
These embeddings had strong performance, but folks wanted to make an improvement by taking into account the distributional 
hypothesis AND utilizing global corpus statistics. This gave rise to GloVe: Global Vectors for Word Representations.
GloVe considers global corpus statistics and the context of words with a co-occurence matrix and a least squares objective.
  

<h3> Reinforcement Learning: Multi-Armbed Bandit Problems</h3> 
We can define elements of reinforcement learning as 
<ul>
    <li> Policy:
        <ul>
            <li>A policy is a mapping from perceived  states of the environemnt to the actions meant to be taken in those states </li>
        </ul
    </li>
    <li> Reward Signal
        <ul>
            <li> During each time step, the environment sends the agent some # whih is the reward signal</li>
            <li> The agent seeks to maximize the reward it receives in the long run</li>
        </ul
    </li>
    <li> Value Function
        <ul>
            <li>While the reward specifies what's good in the intermediate sense, the value function specifies what's good in the long run </li>
            <li>Value = amount of reqard the agent can expect to accumulate over the future starting from it's current state</li>
            <li>Allows us to delay gratification and go to a low reward state if we believe we will get more reward in the long run</li>
        </ul
    </li>
    <li> Optional: Model Of The Environment
        <ul>
            <li> Something that mimics the environment</li>
            <li>Allows us to make inferences about how the environment might behave</li>
            <li>Model might help predict the next state or reward</li>
            <li>Model-Based Methods: Uses models and planning</li>
            <li>Explicitly trail and error learners </li>
        </ul
    </li>
</ul>


<h3> Unsupervised Learning: AutoEncoders, K-Means Clustering </h3> 